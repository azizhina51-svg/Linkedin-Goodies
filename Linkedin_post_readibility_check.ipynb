{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuIORjD8kQq1L8x3sZFZFf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azizhina51-svg/Linkedin-Goodies/blob/main/Linkedin_post_readibility_check.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: install required libraries\n",
        "!pip install -q textstat spacy sentence-transformers scikit-learn pandas\n"
      ],
      "metadata": {
        "id": "IOVdqaBqzuUp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: download spaCy English model (run once)\n",
        "!python -m spacy download en_core_web_sm -q\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3TZKddx2Zx-",
        "outputId": "1031de63-e11c-453a-a9a7-39fc59181708"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3mâš  Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: imports and model initialization\n",
        "import textstat\n",
        "import spacy\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# load models\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "sbert = SentenceTransformer('all-MiniLM-L6-v2')  # lightweight SBERT\n"
      ],
      "metadata": {
        "id": "e2r5hqv02clY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: basic_stats (tokenization, sentence counts, simple heuristics)\n",
        "def basic_stats(text):\n",
        "    doc = nlp(text)\n",
        "    sentences = list(doc.sents)\n",
        "    words = [token.text for token in doc if token.is_alpha]\n",
        "    long_words = [w for w in words if len(w) > 6]\n",
        "    avg_sentence_len = (len(words) / max(1, len(sentences)))\n",
        "    short_sentence_ratio = sum(1 for s in sentences if len([t for t in s if t.is_alpha]) < 8) / max(1, len(sentences))\n",
        "    return {\n",
        "        'num_chars': len(text),\n",
        "        'num_words': len(words),\n",
        "        'num_sentences': len(sentences),\n",
        "        'avg_sentence_len': avg_sentence_len,\n",
        "        'pct_long_words': len(long_words) / max(1, len(words)),\n",
        "        'short_sentence_ratio': short_sentence_ratio\n",
        "    }\n"
      ],
      "metadata": {
        "id": "0KjkjULx2mxZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: compute classic readability formulas via textstat\n",
        "def readability_metrics(text):\n",
        "    return {\n",
        "        'flesch_reading_ease': textstat.flesch_reading_ease(text),\n",
        "        'flesch_kincaid_grade': textstat.flesch_kincaid_grade(text),\n",
        "        'gunning_fog': textstat.gunning_fog(text),\n",
        "        'smog_index': textstat.smog_index(text),\n",
        "        'automated_readability_index': textstat.automated_readability_index(text),\n",
        "        'dale_chall_readability_score': textstat.dale_chall_readability_score(text)\n",
        "    }\n",
        "\n",
        "def normalize_scores(scores_dict):\n",
        "    # Convert different metrics into 0-100 ease score (higher = easier)\n",
        "    out = {}\n",
        "    out['flesch_reading_ease_norm'] = np.clip(scores_dict['flesch_reading_ease'], 0, 100)\n",
        "    def invert_grade(v, max_grade=20):\n",
        "        v = max(0, min(v, max_grade))\n",
        "        return (1 - (v / max_grade)) * 100\n",
        "    out['flesch_kincaid_grade_norm'] = invert_grade(scores_dict['flesch_kincaid_grade'])\n",
        "    out['gunning_fog_norm'] = invert_grade(scores_dict['gunning_fog'])\n",
        "    out['smog_index_norm'] = invert_grade(scores_dict['smog_index'])\n",
        "    out['ari_norm'] = invert_grade(scores_dict['automated_readability_index'])\n",
        "    dc = scores_dict['dale_chall_readability_score']\n",
        "    dc = max(4.0, min(dc, 10.0))\n",
        "    out['dale_chall_norm'] = (1 - ((dc - 4.0) / (10.0 - 4.0))) * 100\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "bhxg5frf2sVj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: composite score combining normalized formulas + heuristics\n",
        "def composite_readability(text, weights=None):\n",
        "    if weights is None:\n",
        "        weights = {\n",
        "            'flesch_reading_ease_norm': 1,\n",
        "            'flesch_kincaid_grade_norm': 1,\n",
        "            'gunning_fog_norm': 1,\n",
        "            'smog_index_norm': 1,\n",
        "            'ari_norm': 1,\n",
        "            'dale_chall_norm': 1\n",
        "        }\n",
        "    r = readability_metrics(text)\n",
        "    rn = normalize_scores(r)\n",
        "    stats = basic_stats(text)\n",
        "    short_sentence_bonus = max(0, (1 - stats['short_sentence_ratio'])) * 10\n",
        "    long_word_penalty = (1 - (1 - stats['pct_long_words'])) * -5\n",
        "    keys = list(weights.keys())\n",
        "    vals = np.array([rn[k] for k in keys], dtype=float)\n",
        "    w = np.array([weights[k] for k in keys], dtype=float)\n",
        "    w = w / w.sum()\n",
        "    core = (vals * w).sum()\n",
        "    composite = core + short_sentence_bonus + long_word_penalty\n",
        "    composite = float(np.clip(composite, 0, 100))\n",
        "    return {\n",
        "        'composite_score': composite,\n",
        "        'component_norms': rn,\n",
        "        'heuristics': stats,\n",
        "        'raw_metrics': r\n",
        "    }\n"
      ],
      "metadata": {
        "id": "rFAn0O-R2wvk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: quick demo using a sample text (run to see outputs)\n",
        "sample_text = \"\"\"Writing for LinkedIn is a mix of clarity and human voice.\n",
        "Use short sentences, avoid jargon, and give a single clear idea per post.\n",
        "Bulleted lists and emojis can help scannability, but too many links hurt readability.\"\"\"\n",
        "\n",
        "result = composite_readability(sample_text)\n",
        "print(\"COMPOSITE READABILITY (0=hard -> 100=super easy):\", result['composite_score'])\n",
        "print(\"\\nNormalized component scores:\")\n",
        "for k,v in result['component_norms'].items():\n",
        "    print(f\"  {k}: {v:.1f}\")\n",
        "print(\"\\nHeuristic stats:\")\n",
        "for k,v in result['heuristics'].items():\n",
        "    print(f\"  {k}: {v:.3f}\")\n",
        "print(\"\\nRaw formula metrics (for debug):\")\n",
        "for k,v in result['raw_metrics'].items():\n",
        "    print(f\"  {k}: {v}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oih0lFNJ3qSC",
        "outputId": "85af58e7-1b2d-4d91-bec8-5ee6c0c53fff"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMPOSITE READABILITY (0=hard -> 100=super easy): 55.70255078667961\n",
            "\n",
            "Normalized component scores:\n",
            "  flesch_reading_ease_norm: 61.7\n",
            "  flesch_kincaid_grade_norm: 61.4\n",
            "  gunning_fog_norm: 48.3\n",
            "  smog_index_norm: 44.0\n",
            "  ari_norm: 61.1\n",
            "  dale_chall_norm: 3.4\n",
            "\n",
            "Heuristic stats:\n",
            "  num_chars: 217.000\n",
            "  num_words: 37.000\n",
            "  num_sentences: 2.000\n",
            "  avg_sentence_len: 18.500\n",
            "  pct_long_words: 0.189\n",
            "  short_sentence_ratio: 0.000\n",
            "\n",
            "Raw formula metrics (for debug):\n",
            "  flesch_reading_ease: 61.70045045045046\n",
            "  flesch_kincaid_grade: 7.717297297297296\n",
            "  gunning_fog: 10.33873873873874\n",
            "  smog_index: 11.20814326018867\n",
            "  automated_readability_index: 7.777477477477479\n",
            "  dale_chall_readability_score: 9.796071171171171\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = \"\"\"Why do I need you? All the info I need is available online.â€ ðŸ¤·ðŸ¼â€â™€ï¸\n",
        "\n",
        "This is a common question I get from professionals who want to build & monetise a personal brand,\n",
        "but are unsure about my Executive Branding Program.\n",
        "-\n",
        "My response to this?\n",
        "\n",
        "This is true.\n",
        "Everything is online.\n",
        "\n",
        "But information ISNâ€™T what gets you results.\n",
        "Itâ€™s so much more than that.\n",
        "\n",
        "My Executive Branding Program works because it gives you everything the internet canâ€™t.\n",
        "\n",
        "It also:\n",
        "1ï¸âƒ£ Holds you accountable,\n",
        "so you do the work between sessions,\n",
        "and donâ€™t let it slip when your 9-5 gets too busy\n",
        "\n",
        "\n",
        "2ï¸âƒ£ Brings real-life experience & answers from someone who has\n",
        "LIVED through it & created systems that WORK for your exact situation\n",
        "\n",
        "(e.g., how to fit everything in when you work a 9-5, 60+ hours a week)\n",
        "\n",
        "\n",
        "3ï¸âƒ£ Works on not just technical knowledge,\n",
        "but the IDENTITY shifts that are required to take\n",
        "your online business and presence where you want to go\n",
        "\n",
        "(e.g., moving past the fear of being seen, dealing with the potential judgment from family & friends)\n",
        "\n",
        "\n",
        "4ï¸âƒ£ Being able to provide an objective perspective,\n",
        "when reviewing your positioning, content, and overall strategy,\n",
        "because itâ€™s now second nature to me & so much easier to pick up on things the untrained eye doesnâ€™t see\n",
        "\n",
        "(e.g., is your post audience-focused? Or just about you?\n",
        "But then, is there enough of your personality injected into it too?)\n",
        "\n",
        "\n",
        "5ï¸âƒ£ Being able to access ALL of the information at the right time,\n",
        "and focusing/deep-diving on where you need the most support,\n",
        "or where you could move much faster\n",
        "\n",
        "\n",
        "6ï¸âƒ£ Having someone that believes in you, supports you,\n",
        "and gives you the confidence to show up online,\n",
        "long before you believe it yourself\n",
        "\n",
        "(Something I wish I had long long ago)\n",
        "\n",
        "\n",
        "So yeah, you CAN find all the technical knowledge online.\n",
        "But you wonâ€™t get the speed, clarity, confidence, and personalised strategy,\n",
        "that only comes with experience & talking to a real person ðŸ¤ðŸ¼.\"\"\"\n",
        "\n",
        "result = composite_readability(sample_text)\n",
        "print(\"COMPOSITE READABILITY (0=hard -> 100=super easy):\", result['composite_score'])\n",
        "print(\"\\nNormalized component scores:\")\n",
        "for k,v in result['component_norms'].items():\n",
        "    print(f\"  {k}: {v:.1f}\")\n",
        "print(\"\\nHeuristic stats:\")\n",
        "for k,v in result['heuristics'].items():\n",
        "    print(f\"  {k}: {v:.3f}\")\n",
        "print(\"\\nRaw formula metrics (for debug):\")\n",
        "for k,v in result['raw_metrics'].items():\n",
        "    print(f\"  {k}: {v}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6n1T7WK3-_4",
        "outputId": "e2d8b81a-e932-4675-bef3-b18046f39e83"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMPOSITE READABILITY (0=hard -> 100=super easy): 45.853699551784736\n",
            "\n",
            "Normalized component scores:\n",
            "  flesch_reading_ease_norm: 60.6\n",
            "  flesch_kincaid_grade_norm: 52.3\n",
            "  gunning_fog_norm: 39.7\n",
            "  smog_index_norm: 40.5\n",
            "  ari_norm: 48.5\n",
            "  dale_chall_norm: 8.3\n",
            "\n",
            "Heuristic stats:\n",
            "  num_chars: 1932.000\n",
            "  num_words: 315.000\n",
            "  num_sentences: 15.000\n",
            "  avg_sentence_len: 21.000\n",
            "  pct_long_words: 0.225\n",
            "  short_sentence_ratio: 0.467\n",
            "\n",
            "Raw formula metrics (for debug):\n",
            "  flesch_reading_ease: 60.590294117647076\n",
            "  flesch_kincaid_grade: 9.542941176470592\n",
            "  gunning_fog: 12.06797385620915\n",
            "  smog_index: 11.892052765847286\n",
            "  automated_readability_index: 10.291573926868047\n",
            "  dale_chall_readability_score: 9.504009005083514\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = \"\"\"Most of you treat LinkedIn like itâ€™s a Hogwarts potions exam and Professor Snape is glaring at you from two feet away.\n",
        "\n",
        "Drop 17 comments before posting.\n",
        "Reply to all recent DMs.\n",
        "Add a bit of bezoar.\n",
        "Mix it with some murtlap tentacles.\n",
        "Finish it off with mistletoe berries.\n",
        "\n",
        "Seriously, please stop.\n",
        "\n",
        "Here are 4 things that actually move the needle:\n",
        "\n",
        "1. Write interesting posts that actually feel like they were written by a living, breathing human. (Or get someone to do it for you)\n",
        "\n",
        "2. Add relevant people to your network. (Creators and target audience)\n",
        "\n",
        "3. Spend time in the DMs. Get those conversations going.\n",
        "\n",
        "4. Support your peers via comments.\n",
        "\n",
        "That's it. Everything else is just noise that is distracting you from the real stuff.\n",
        "\n",
        "Take my advice, keep things simple. Simple works.\n",
        "\n",
        "(If you don't believe me, just ask Harry)\n",
        "\"\"\"\n",
        "\n",
        "result = composite_readability(sample_text)\n",
        "\n",
        "print(\"COMPOSITE READABILITY (0=hard -> 100=super easy):\", result['composite_score'])\n",
        "print(\"\\nNormalized component scores:\")\n",
        "for k, v in result['component_norms'].items():\n",
        "    print(f\"  {k}: {v:.1f}\")\n",
        "\n",
        "print(\"\\nHeuristic stats:\")\n",
        "for k, v in result['heuristics'].items():\n",
        "    print(f\"  {k}: {v:.3f}\")\n",
        "\n",
        "print(\"\\nRaw formula metrics (for debug):\")\n",
        "for k, v in result['raw_metrics'].items():\n",
        "    print(f\"  {k}: {v}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ieqp21Vu5Owf",
        "outputId": "f31de520-ef9b-40cc-80c4-47c44f3d70f0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMPOSITE READABILITY (0=hard -> 100=super easy): 65.25297645711399\n",
            "\n",
            "Normalized component scores:\n",
            "  flesch_reading_ease_norm: 77.5\n",
            "  flesch_kincaid_grade_norm: 77.9\n",
            "  gunning_fog_norm: 68.7\n",
            "  smog_index_norm: 60.1\n",
            "  ari_norm: 75.8\n",
            "  dale_chall_norm: 16.7\n",
            "\n",
            "Heuristic stats:\n",
            "  num_chars: 833.000\n",
            "  num_words: 137.000\n",
            "  num_sentences: 20.000\n",
            "  avg_sentence_len: 6.850\n",
            "  pct_long_words: 0.204\n",
            "  short_sentence_ratio: 0.650\n",
            "\n",
            "Raw formula metrics (for debug):\n",
            "  flesch_reading_ease: 77.49166860916864\n",
            "  flesch_kincaid_grade: 4.42441724941725\n",
            "  gunning_fog: 6.254700854700855\n",
            "  smog_index: 7.984000788550335\n",
            "  automated_readability_index: 4.8406138306138295\n",
            "  dale_chall_readability_score: 8.999425563325564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: optional - compute SBERT embedding for downstream ML\n",
        "emb = sbert.encode([sample_text])[0]\n",
        "print(\"Sentence embedding vector length:\", len(emb))\n",
        "# Save embedding to a DataFrame for example\n",
        "df_emb = pd.DataFrame([emb])\n",
        "df_emb.to_csv(\"sample_embedding.csv\", index=False)\n",
        "print(\"Saved embedding to sample_embedding.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTgntYrb3XCq",
        "outputId": "eebc1517-46f8-4a80-dcdd-9604be329a70"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence embedding vector length: 384\n",
            "Saved embedding to sample_embedding.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import textstat\n",
        "import spacy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load NLP and embedding models\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "sbert = SentenceTransformer('all-MiniLM-L6-v2')\n"
      ],
      "metadata": {
        "id": "OjHymUazCoT2"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def basic_stats(text):\n",
        "    doc = nlp(text)\n",
        "    sentences = list(doc.sents)\n",
        "    words = [token.text for token in doc if token.is_alpha]\n",
        "    long_words = [w for w in words if len(w) > 6]\n",
        "    avg_sentence_len = (len(words) / max(1, len(sentences)))\n",
        "    short_sentence_ratio = sum(1 for s in sentences if len([t for t in s if t.is_alpha]) < 8) / max(1, len(sentences))\n",
        "    return {\n",
        "        'num_chars': len(text),\n",
        "        'num_words': len(words),\n",
        "        'num_sentences': len(sentences),\n",
        "        'avg_sentence_len': avg_sentence_len,\n",
        "        'pct_long_words': len(long_words) / max(1, len(words)),\n",
        "        'short_sentence_ratio': short_sentence_ratio\n",
        "    }\n",
        "\n",
        "def readability_metrics(text):\n",
        "    return {\n",
        "        'flesch_reading_ease': textstat.flesch_reading_ease(text),\n",
        "        'flesch_kincaid_grade': textstat.flesch_kincaid_grade(text),\n",
        "        'gunning_fog': textstat.gunning_fog(text),\n",
        "        'smog_index': textstat.smog_index(text),\n",
        "        'automated_readability_index': textstat.automated_readability_index(text),\n",
        "        'dale_chall_readability_score': textstat.dale_chall_readability_score(text)\n",
        "    }\n",
        "\n",
        "def normalize_scores(scores_dict):\n",
        "    out = {}\n",
        "    out['flesch_reading_ease_norm'] = np.clip(scores_dict['flesch_reading_ease'], 0, 100)\n",
        "    def invert_grade(v, max_grade=20):\n",
        "        v = max(0, min(v, max_grade))\n",
        "        return (1 - (v / max_grade)) * 100\n",
        "    out['flesch_kincaid_grade_norm'] = invert_grade(scores_dict['flesch_kincaid_grade'])\n",
        "    out['gunning_fog_norm'] = invert_grade(scores_dict['gunning_fog'])\n",
        "    out['smog_index_norm'] = invert_grade(scores_dict['smog_index'])\n",
        "    out['ari_norm'] = invert_grade(scores_dict['automated_readability_index'])\n",
        "    dc = scores_dict['dale_chall_readability_score']\n",
        "    dc = max(4.0, min(dc, 10.0))\n",
        "    out['dale_chall_norm'] = (1 - ((dc - 4.0) / (10.0 - 4.0))) * 100\n",
        "    return out\n",
        "\n",
        "def composite_readability(text, weights=None):\n",
        "    if weights is None:\n",
        "        weights = {\n",
        "            'flesch_reading_ease_norm': 1,\n",
        "            'flesch_kincaid_grade_norm': 1,\n",
        "            'gunning_fog_norm': 1,\n",
        "            'smog_index_norm': 1,\n",
        "            'ari_norm': 1,\n",
        "            'dale_chall_norm': 1\n",
        "        }\n",
        "    r = readability_metrics(text)\n",
        "    rn = normalize_scores(r)\n",
        "    stats = basic_stats(text)\n",
        "    short_sentence_bonus = max(0, (1 - stats['short_sentence_ratio'])) * 10\n",
        "    long_word_penalty = (1 - (1 - stats['pct_long_words'])) * -5\n",
        "    keys = list(weights.keys())\n",
        "    vals = np.array([rn[k] for k in keys], dtype=float)\n",
        "    w = np.array([weights[k] for k in keys], dtype=float)\n",
        "    w = w / w.sum()\n",
        "    core = (vals * w).sum()\n",
        "    composite = core + short_sentence_bonus + long_word_penalty\n",
        "    composite = float(np.clip(composite, 0, 100))\n",
        "    return {\n",
        "        'composite_score': composite,\n",
        "        'component_norms': rn,\n",
        "        'heuristics': stats,\n",
        "        'raw_metrics': r\n",
        "    }\n"
      ],
      "metadata": {
        "id": "Qjd5cQqeCqvC"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "st.title(\"LinkedIn Post Readability Tool\")\n",
        "st.write(\"Paste your LinkedIn post below to see the readability analysis.\")\n",
        "\n",
        "user_input = st.text_area(\"Your LinkedIn Post\", height=250)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGX8AVLgC8Ue",
        "outputId": "3e072bf3-2d96-4323-a636-6c7f46653bf5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-12-09 07:38:07.712 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-09 07:38:07.714 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-09 07:38:07.715 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-09 07:38:07.716 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-09 07:38:07.717 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-09 07:38:07.719 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-09 07:38:07.721 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-09 07:38:07.722 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-09 07:38:07.723 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-09 07:38:07.723 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-09 07:38:07.725 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-09 07:38:07.725 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-09 07:38:07.726 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if st.button(\"Analyze\"):\n",
        "    if len(user_input.strip()) == 0:\n",
        "        st.warning(\"Please enter some text first!\")\n",
        "    else:\n",
        "        result = composite_readability(user_input)\n",
        "        st.subheader(f\"Composite Readability Score: {result['composite_score']:.1f}/100\")\n",
        "\n",
        "        # Show normalized component scores as a bar chart\n",
        "        comp_df = pd.DataFrame(result['component_norms'], index=[\"Score\"]).T\n",
        "        st.bar_chart(comp_df)\n",
        "\n",
        "        # Show heuristic stats as a table\n",
        "        heur_df = pd.DataFrame(result['heuristics'], index=[\"Value\"]).T\n",
        "        st.subheader(\"Heuristic Stats\")\n",
        "        st.table(heur_df)\n",
        "\n",
        "        # Optional: embedding vector\n",
        "        emb = sbert.encode([user_input])[0]\n",
        "        st.write(f\"Sentence embedding vector length: {len(emb)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHV1mm-DDCCu",
        "outputId": "f9681282-6073-437a-dbf6-f58467eb7d8b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-12-09 07:38:31.370 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-09 07:38:31.370 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-09 07:38:31.371 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-09 07:38:31.372 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-09 07:38:31.373 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-09 07:38:31.374 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcwwi-pqDTVW",
        "outputId": "8ad46626-4129-4f23-fb7c-d4bceeb1dbd2"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.5.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Downloading pyngrok-7.5.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import textstat\n",
        "import spacy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load models\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "sbert = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Helper functions\n",
        "def basic_stats(text):\n",
        "    doc = nlp(text)\n",
        "    sentences = list(doc.sents)\n",
        "    words = [token.text for token in doc if token.is_alpha]\n",
        "    long_words = [w for w in words if len(w) > 6]\n",
        "    avg_sentence_len = (len(words) / max(1, len(sentences)))\n",
        "    short_sentence_ratio = sum(1 for s in sentences if len([t for t in s if t.is_alpha]) < 8) / max(1, len(sentences))\n",
        "    return {\n",
        "        'num_chars': len(text),\n",
        "        'num_words': len(words),\n",
        "        'num_sentences': len(sentences),\n",
        "        'avg_sentence_len': avg_sentence_len,\n",
        "        'pct_long_words': len(long_words) / max(1, len(words)),\n",
        "        'short_sentence_ratio': short_sentence_ratio\n",
        "    }\n",
        "\n",
        "def readability_metrics(text):\n",
        "    return {\n",
        "        'flesch_reading_ease': textstat.flesch_reading_ease(text),\n",
        "        'flesch_kincaid_grade': textstat.flesch_kincaid_grade(text),\n",
        "        'gunning_fog': textstat.gunning_fog(text),\n",
        "        'smog_index': textstat.smog_index(text),\n",
        "        'automated_readability_index': textstat.automated_readability_index(text),\n",
        "        'dale_chall_readability_score': textstat.dale_chall_readability_score(text)\n",
        "    }\n",
        "\n",
        "def normalize_scores(scores_dict):\n",
        "    out = {}\n",
        "    out['flesch_reading_ease_norm'] = np.clip(scores_dict['flesch_reading_ease'], 0, 100)\n",
        "    def invert_grade(v, max_grade=20):\n",
        "        v = max(0, min(v, max_grade))\n",
        "        return (1 - (v / max_grade)) * 100\n",
        "    out['flesch_kincaid_grade_norm'] = invert_grade(scores_dict['flesch_kincaid_grade'])\n",
        "    out['gunning_fog_norm'] = invert_grade(scores_dict['gunning_fog'])\n",
        "    out['smog_index_norm'] = invert_grade(scores_dict['smog_index'])\n",
        "    out['ari_norm'] = invert_grade(scores_dict['automated_readability_index'])\n",
        "    dc = scores_dict['dale_chall_readability_score']\n",
        "    dc = max(4.0, min(dc, 10.0))\n",
        "    out['dale_chall_norm'] = (1 - ((dc - 4.0) / (10.0 - 4.0))) * 100\n",
        "    return out\n",
        "\n",
        "def composite_readability(text, weights=None):\n",
        "    if weights is None:\n",
        "        weights = {\n",
        "            'flesch_reading_ease_norm': 1,\n",
        "            'flesch_kincaid_grade_norm': 1,\n",
        "            'gunning_fog_norm': 1,\n",
        "            'smog_index_norm': 1,\n",
        "            'ari_norm': 1,\n",
        "            'dale_chall_norm': 1\n",
        "        }\n",
        "    r = readability_metrics(text)\n",
        "    rn = normalize_scores(r)\n",
        "    stats = basic_stats(text)\n",
        "    short_sentence_bonus = max(0, (1 - stats['short_sentence_ratio'])) * 10\n",
        "    long_word_penalty = (1 - (1 - stats['pct_long_words'])) * -5\n",
        "    keys = list(weights.keys())\n",
        "    vals = np.array([rn[k] for k in keys], dtype=float)\n",
        "    w = np.array([weights[k] for k in keys], dtype=float)\n",
        "    w = w / w.sum()\n",
        "    core = (vals * w).sum()\n",
        "    composite = core + short_sentence_bonus + long_word_penalty\n",
        "    composite = float(np.clip(composite, 0, 100))\n",
        "    return {\n",
        "        'composite_score': composite,\n",
        "        'component_norms': rn,\n",
        "        'heuristics': stats,\n",
        "        'raw_metrics': r\n",
        "    }\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"LinkedIn Post Readability Tool\")\n",
        "st.write(\"Paste your LinkedIn post below to see the readability analysis.\")\n",
        "\n",
        "user_input = st.text_area(\"Your LinkedIn Post\", height=250)\n",
        "\n",
        "if st.button(\"Analyze\"):\n",
        "    if len(user_input.strip()) == 0:\n",
        "        st.warning(\"Please enter some text first!\")\n",
        "    else:\n",
        "        result = composite_readability(user_input)\n",
        "        st.subheader(f\"Composite Readability Score: {result['composite_score']:.1f}/100\")\n",
        "\n",
        "        # Show normalized component scores as a bar chart\n",
        "        comp_df = pd.DataFrame(result['component_norms'], index=[\"Score\"]).T\n",
        "        st.bar_chart(comp_df)\n",
        "\n",
        "        # Show heuristic stats as a table\n",
        "        heur_df = pd.DataFrame(result['heuristics'], index=[\"Value\"]).T\n",
        "        st.subheader(\"Heuristic Stats\")\n",
        "        st.table(heur_df)\n",
        "\n",
        "        # Optional: embedding vector\n",
        "        emb = sbert.encode([user_input])[0]\n",
        "        st.write(f\"Sentence embedding vector length: {len(emb)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6nk2WxWDZEv",
        "outputId": "fcb1e397-72fc-4aa5-d45f-fe0d60070a84"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install pyngrok if not already installed\n",
        "!pip install -q pyngrok\n",
        "\n",
        "# Import ngrok\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Set your ngrok auth token here\n",
        "NGROK_AUTH_TOKEN = \"36VZIQ8m0uq9JSWzt6NpbL9wD1k_7kASWUcjeHJxbnjqExtad\"  # <-- Replace with your token\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "# Optional: test connection by opening a tunnel (not required if you already ran it)\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"Streamlit public URL:\", public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_9cb9fpKI_k",
        "outputId": "3723add7-3950-4e6e-ce9f-5474aef78e7f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit public URL: NgrokTunnel: \"https://unindustrialized-iesha-uncomplimented.ngrok-free.dev\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}